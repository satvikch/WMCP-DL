{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzr1SgDxAfTh"
      },
      "source": [
        "# Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "574pNxc_AfTj"
      },
      "outputs": [],
      "source": [
        "import numbers\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "import numpy as np\n",
        "from skimage import io, util\n",
        "import sklearn.feature_extraction as sk\n",
        "# from ksvd import ApproximateKSVD\n",
        "import cv2\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdhK343kAfTp"
      },
      "source": [
        "# KSVD CLASS \n",
        "\n",
        "## Ksvd class for training the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k2c3cSHRAfTq"
      },
      "outputs": [],
      "source": [
        "# coding:utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from sklearn.linear_model import orthogonal_mp_gram\n",
        "import math\n",
        "\n",
        "\n",
        "class ApproximateKSVD(object):\n",
        "    def __init__(self, n_components, max_iter=1, diction = None, tol=1e-6,\n",
        "                 transform_n_nonzero_coefs = None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_components:\n",
        "            Number of dictionary elements\n",
        "\n",
        "        max_iter:\n",
        "            Maximum number of iterations\n",
        "\n",
        "        tol:\n",
        "            tolerance for error\n",
        "\n",
        "        transform_n_nonzero_coefs:\n",
        "            Number of nonzero coefficients to target\n",
        "        \"\"\"\n",
        "        self.components_ = None\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.n_components = n_components\n",
        "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
        "        self.D = diction\n",
        "\n",
        "    def _update_dict(self, X, D, gamma):\n",
        "        for j in range(self.n_components):\n",
        "            I = gamma[:, j] > 0\n",
        "            if np.sum(I) == 0:\n",
        "                continue\n",
        "\n",
        "            D[j, :] = 0\n",
        "            g = gamma[I, j].T\n",
        "#             print(gamma.shape)\n",
        "#             print(X.shape)\n",
        "#             print(len(I))\n",
        "            r = X[I, :] - gamma[I, :].dot(D)\n",
        "            d = r.T.dot(g)\n",
        "            d /= np.linalg.norm(d)\n",
        "            g = r.dot(d)\n",
        "            D[j, :] = d\n",
        "            gamma[I, j] = g.T\n",
        "        return D, gamma\n",
        "\n",
        "    def _initialize(self, X):\n",
        "        if min(X.shape) < self.n_components:\n",
        "            D = np.random.randn(self.n_components, X.shape[1])\n",
        "#             print(\"Dictionary:\", D.shape)\n",
        "        else:\n",
        "            u, s, vt = sp.sparse.linalg.svds(X, k=self.n_components)\n",
        "            D = np.dot(np.diag(s), vt)\n",
        "        D /= np.linalg.norm(D, axis=1)[:, np.newaxis]\n",
        "        return D\n",
        "\n",
        "    def _transform(self, D, X):\n",
        "        gram = D.dot(D.T)\n",
        "#         print(\"Gamma:\", gram.shape)\n",
        "        Xy = D.dot(X.T)\n",
        "#         print(\"Xy:\", Xy.shape)\n",
        "\n",
        "        n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
        "        if n_nonzero_coefs is None:\n",
        "            n_nonzero_coefs = int(0.1 * D.shape[0])\n",
        "            print(\"non-zero\", n_nonzero_coefs)\n",
        "        else:\n",
        "            print(\"Non-zero\", n_nonzero_coefs)\n",
        "\n",
        "        return orthogonal_mp_gram(\n",
        "            gram, Xy, n_nonzero_coefs=n_nonzero_coefs).T\n",
        "\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: shape = [n_samples, n_features]\n",
        "        \"\"\"\n",
        "        # print(X)\n",
        "        # print(X.shape[1])\n",
        "        y = []\n",
        "        avg = []\n",
        "        # D = self.D\n",
        "        D = self._initialize(X)\n",
        "        transform_n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
        "        for i in range(self.max_iter):\n",
        "            gamma = self._transform(D, X)\n",
        "            e = np.linalg.norm(X - gamma.dot(D))\n",
        "            y.append(e)\n",
        "            print(\"||Y - DX||2 for iteration {0} is: \".format(i+1), e)\n",
        "            if e < self.tol:\n",
        "                break\n",
        "            D, gamma = self._update_dict(X, D, gamma)\n",
        "\n",
        "        plt.plot(y)\n",
        "        with open(\"sigma_10_0.3.txt\", \"wb\") as fp:   #Pickling\n",
        "            pickle.dump(y, fp)\n",
        "        plt.show()\n",
        "\n",
        "        self.components_ = D\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self._transform(self.components_, X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DobaPzAfTv"
      },
      "source": [
        "# Function to compute the number of patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "si8zQpODAfTw"
      },
      "outputs": [],
      "source": [
        "def _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches=None):\n",
        "\n",
        "    n_h = (i_h - p_h) // step + 1\n",
        "    n_w = (i_w - p_w) // step + 1\n",
        "    all_patches = n_h * n_w\n",
        "\n",
        "    return all_patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulXTTv1hAfT0"
      },
      "source": [
        "# Function to extract the patches from Input Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PJ4mlSd3AfT4"
      },
      "outputs": [],
      "source": [
        "def _extracting(arr, patch_shape=8, extraction_step=1):\n",
        "\n",
        "    arr_ndim = arr.ndim\n",
        "\n",
        "    if isinstance(patch_shape, numbers.Number):\n",
        "        patch_shape = tuple([patch_shape] * arr_ndim)\n",
        "    if isinstance(extraction_step, numbers.Number):\n",
        "        extraction_step = tuple([extraction_step] * arr_ndim)\n",
        "\n",
        "    patch_strides = arr.strides\n",
        "\n",
        "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
        "    indexing_strides = arr[slices].strides\n",
        "\n",
        "    patch_indices_shape = ((np.array(arr.shape) - np.array(patch_shape)) //\n",
        "                           np.array(extraction_step)) + 1\n",
        "\n",
        "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
        "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
        "\n",
        "    patches = as_strided(arr, shape=shape, strides=strides)\n",
        "\n",
        "    # patches = patches.reshape([-1] + list(patch_shape))\n",
        "\n",
        "    return patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziE9sZefAfT8"
      },
      "source": [
        "# Function to call the extraction step and reshaping the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LDj5VVOHAfT9"
      },
      "outputs": [],
      "source": [
        "def extract_patches(image, patch_size, step, max_patches=None, random_state=None):\n",
        "\n",
        "    i_h, i_w = image.shape[:2]\n",
        "    p_h, p_w = patch_size\n",
        "\n",
        "    # image = check_array(image, allow_nd=True)\n",
        "    image = image.reshape((i_h, i_w, -1))\n",
        "    n_colors = image.shape[-1]\n",
        "\n",
        "    extracted_patches = _extracting(image, patch_shape=(p_h, p_w, n_colors), extraction_step=step) # above function call\n",
        "    n_patches = _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches)\n",
        "    # print n_patches\n",
        "    # if max_patches:\n",
        "    #     rng = check_random_state(random_state)\n",
        "    #     i_s = rng.randint(i_h - p_h + step, size=n_patches)\n",
        "    #     j_s = rng.randint(i_w - p_w + step, size=n_patches)\n",
        "    #     patches = extracted_patches[i_s, j_s, 0]\n",
        "    # else:\n",
        "    patches = extracted_patches\n",
        "\n",
        "    patches = patches.reshape(-1, p_h, p_w, n_colors)\n",
        "    # print patches.shape\n",
        "    # remove the color dimension if useless\n",
        "    if patches.shape[-1] == 1:\n",
        "        return patches.reshape(n_patches, p_h, p_w)\n",
        "    else:\n",
        "        return patches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azUTsSwBAfUH"
      },
      "source": [
        "# Funtion for Reconstruction of the image from the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vnAzCvM6AfUK"
      },
      "outputs": [],
      "source": [
        "def reconstruct_patches(patches, image_size, step):\n",
        "\n",
        "    i_h, i_w = image_size[:2]\n",
        "    p_h, p_w = patches.shape[1:3]\n",
        "    img = np.zeros(image_size)\n",
        "    # compute the dimensions of the patches array\n",
        "    n_h = int((i_h - p_h) / step + 1)\n",
        "    n_w = int((i_w - p_w) / step + 1)\n",
        "    for p, (i, j) in zip(patches, product(range(n_h), range(n_w))):\n",
        "        img[i * step:i * step + p_h, j * step:j * step + p_w] += p\n",
        "\n",
        "    for i in range(i_h):\n",
        "        for j in range(i_w):\n",
        "            img[i, j] /= float(min(i + step, p_h, i_h - i) *\n",
        "                               min(j + step, p_w, i_w - j))\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGdFwt_hAfUb"
      },
      "source": [
        "# If the input image is not noisy, function to add noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIHbHA_VAfUc"
      },
      "outputs": [],
      "source": [
        "img = util.img_as_float(io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/input/Lenna.jpg\"))\n",
        "print(\"Adding Noise\")\n",
        "img_with_noise = util.random_noise(img, seed=1)\n",
        "io.imsave(\"noise.png\", img_with_noise)\n",
        "print(\"Done with noise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjaek6-FAfUo"
      },
      "source": [
        "# Loading of Image and Extracting patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_2bUVGtAfUr",
        "outputId": "231fe6e3-1682-4bed-afd2-94c3cabc84a6"
      },
      "outputs": [],
      "source": [
        "img = util.img_as_float(cv2.imread(\"girl_face_noise_15.jpg\", 0))\n",
        "# image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/Prova.jpg\")\n",
        "\n",
        "res = extract_patches(img, (8, 8), 1)\n",
        "# width, height, col= res.shape\n",
        "# print(\"initial Image shape\", img.shape)\n",
        "print(\"Patches shape: \", res.shape)\n",
        "num_patch, p_h, p_w = res.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMg7ecBXAfUx"
      },
      "source": [
        "# Functions for converting 2d or 3d matrix to vector and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9eFxZ7EmAfUy"
      },
      "outputs": [],
      "source": [
        "def matrix_to_vector(matrix, patch_size):\n",
        "    \n",
        "    list = np.split(matrix.reshape(-1,patch_size),matrix.shape[0])\n",
        "    \n",
        "    list1 = []\n",
        "    \n",
        "    \n",
        "    for arr in list:\n",
        "        bb = arr.flatten('F').reshape(patch_size**2,1)\n",
        "        list1.append(bb)\n",
        "\n",
        "    array = np.array(list1).squeeze()\n",
        "    \n",
        "    return array\n",
        "\n",
        "\n",
        "def vector_to_matrix_2d(vector,h,w):\n",
        "    \n",
        "    ab = np.reshape(vector,(h,w))\n",
        "    return ab.T\n",
        "\n",
        "def vector_to_matrix_3d(vector, h, w, col):\n",
        "\n",
        "    ab = np.reshape(vector,(h,w,col))\n",
        "#     print(ab.T)\n",
        "    return ab.transpose(0,2,1)\n",
        "\n",
        "\n",
        "# aa= np.array(range(27)).reshape(3,3,3)\n",
        "# print(aa)\n",
        "# print(\"------------------------\")\n",
        "\n",
        "# bb = matrix_to_vector(aa, 3)\n",
        "# print(bb)\n",
        "\n",
        "# ab = vector_to_matrix_3d(array, -1,3,3)\n",
        "# print(ab)\n",
        "\n",
        "# ba = vector_to_matrix_2d(bb[0], 3, 3)\n",
        "# print(ba)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkAI0sL_AfU1"
      },
      "source": [
        "# Pre-Processing step: Removing the mean from each value of the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9B3X3QBVAfU3",
        "outputId": "c28c50cc-1308-40d4-aed0-4f275ce65f14"
      },
      "outputs": [],
      "source": [
        "imag = res[1]\n",
        "print(imag.shape)\n",
        "io.imshow(imag, cmap= 'gray')\n",
        "io.show()\n",
        "\n",
        "signals = matrix_to_vector(res, p_w)\n",
        "\n",
        "num_patches, patch_size = signals.shape\n",
        "\n",
        "print(\"Signals final shape\", signals.shape)\n",
        "mean = np.mean(signals, axis=0)[:, np.newaxis]\n",
        "print(\"Mean value shape: \", mean.shape)\n",
        "\n",
        "mean1 = vector_to_matrix_2d(mean,p_h,p_w)\n",
        "io.imshow(mean1, cmap = 'gray')\n",
        "io.show()\n",
        "\n",
        "signals = (signals.T - mean).T\n",
        "\n",
        "signals1 = vector_to_matrix_2d(signals[1], p_h, p_w)\n",
        "io.imshow(signals1, cmap = 'gray')\n",
        "io.show()\n",
        "\n",
        "signal_final = signals1 + mean1\n",
        "\n",
        "io.imshow(signal_final,  cmap= 'gray')\n",
        "io.show()\n",
        "\n",
        "if signal_final.all() == imag.all():\n",
        "    print(\"True\")\n",
        "else:\n",
        "    print(\"false\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrfXWeyXAfVG"
      },
      "source": [
        "# Applying KSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "E0UuW2njAfVK",
        "outputId": "db24fe12-2498-48b2-d21b-3782e07e4230"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "dict_list = []\n",
        "gamma_list = []\n",
        "\n",
        "# bdict = sio.loadmat('dictionary_intialize.mat') (Predefined Dictionary)\n",
        "# for rel in bdict:\n",
        "#    if rel == 'dictionary':\n",
        "#       diction = bdict['dictionary']\n",
        "\n",
        "# print(diction.shape)\n",
        "\n",
        "print(\"Applying KSVD\")\n",
        "aksvd = ApproximateKSVD(n_components=128, transform_n_nonzero_coefs = 10)\n",
        "dictionary = aksvd.fit(signals[:10000]).components_\n",
        "#dictionary = aksvd.fit(signals)\n",
        "print(\"Done with learning\")\n",
        "# np.savetxt(\"test.txt\", dictionary)\n",
        "gamma = aksvd.transform(signals)\n",
        "print(\"Found gamma\")\n",
        "\n",
        "# import scipy.io as sio \n",
        "\n",
        "# adict = {}\n",
        "# adict['dictionary'] = dictionary\n",
        "\n",
        "# sio.savemat('dictionary_Coeff_{}.mat'.format(30), adict) % Save the trained dictionary\n",
        "\n",
        "# bdict = sio.loadmat('dictionary_Coeff_{}.mat'.format(30))\n",
        "# for rel in bdict:\n",
        "#     print(rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "1t5u9IfAAfVX",
        "outputId": "70c5468c-2628-4510-8318-8d9a5bb7d564"
      },
      "outputs": [],
      "source": [
        "print(dictionary[1].shape)\n",
        "element = dictionary[1] + mean.T\n",
        "print(element.shape)\n",
        "element_1 = vector_to_matrix_2d(element, p_h, p_w)\n",
        "io.imshow(element_1, cmap = 'gray')\n",
        "io.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81zY-jNwAfVe"
      },
      "source": [
        "# Function for extracting images (patches) from Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uzKswd-vAfVf"
      },
      "outputs": [],
      "source": [
        "from tempfile import TemporaryFile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = os.path.join(folder, filename)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZWfND6AfVi"
      },
      "source": [
        "# Function to load the dictionary and convert to patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwOOp0JjAfVj",
        "outputId": "ef8b3aa3-a47d-49f8-c62e-4748e8d1d1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 128)\n"
          ]
        }
      ],
      "source": [
        "dictionary1 = dictionary.T + mean\n",
        "\n",
        "file = dictionary1\n",
        "print(file.shape)\n",
        "\n",
        "K = file.shape[1]\n",
        "# file1 = file.T\n",
        "# print(file1.shape)\n",
        "\n",
        "i = 0\n",
        "k = 0\n",
        "a = np.zeros((8, 16))\n",
        "b = np.zeros((8, 8))\n",
        "result = []\n",
        "#\n",
        "while k < file.shape[1]:\n",
        "    arr = file[:,k]\n",
        "    # a, b = split_array(arr)\n",
        "    a = np.reshape(arr, (-1, 8))\n",
        "    # b = np.reshape(b, (-1, 8))\n",
        "\n",
        "    result.append(a)\n",
        "\n",
        "    k += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQqGxJr-AfVs"
      },
      "source": [
        "# Save each extracted patch as an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSmrgGgOAfVy",
        "outputId": "2312b4b4-08a4-4a66-8164-9e06b76f4626"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "\n",
        "for i in range(result.__len__()):\n",
        "    path = 'jup_images'\n",
        "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), result[i])\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhzCLseIAfV4"
      },
      "source": [
        "# Load the images and concatenate them to save as a single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "All5e1JQAfV5"
      },
      "outputs": [],
      "source": [
        "image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/img_0.jpg\")\n",
        "\n",
        "images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/\")\n",
        "\n",
        "BLUE = [0, 0, 0]\n",
        "final = []\n",
        "\n",
        "for img in images:\n",
        "    img = cv2.imread(img)\n",
        "    de_img= cv2.copyMakeBorder(img,1,1,1,1,cv2.BORDER_CONSTANT,value= BLUE)\n",
        "    final.append(de_img)\n",
        "    \n",
        "count = 0\n",
        "\n",
        "for i in range(final.__len__()):\n",
        "    path = 'jup_images_final'\n",
        "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), final[i])\n",
        "    count += 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "final_images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images_final/\")\n",
        "\n",
        "new_im = Image.new('RGB', (80, 160))\n",
        "\n",
        "x_offset = 0\n",
        "y_offset = 0\n",
        "count = 0\n",
        "\n",
        "i = 0\n",
        "k = 0\n",
        "j = 0\n",
        "\n",
        "# for img in images:\n",
        "#     imga = io.imread(img)\n",
        "#     count += 1\n",
        "#     print(count)\n",
        "#     io.imshow(imga)\n",
        "#     io.show()\n",
        "\n",
        "\n",
        "while j < 16:\n",
        "    while i < 8:\n",
        "        # fin = open(image)  # open the file\n",
        "        img = Image.open(final_images[k])\n",
        "        ext_img = img\n",
        "        new_im.paste(ext_img, (x_offset, y_offset))\n",
        "        x_offset += img.size[0]\n",
        "        i += 1\n",
        "        print('yes x_{0}'.format(i))\n",
        "        print('yes k_{0}'.format(k))\n",
        "        print(\"Offset x: \", x_offset)\n",
        "        k += 1\n",
        "    i = 0\n",
        "    y_offset += img.size[1]\n",
        "    x_offset = 0\n",
        "    j += 1\n",
        "    print('yes y_{0}'.format(j))\n",
        "    print(\"Y-offset\", y_offset)\n",
        "\n",
        "print(\"X:\", x_offset)\n",
        "print(\"Y:\", y_offset)\n",
        "\n",
        "new_im.save('test2.jpg')\n",
        "\n",
        "imagee = io.imread(\"test2.jpg\")\n",
        "io.imshow(imagee)\n",
        "io.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RtZrvX2AfV_"
      },
      "source": [
        "# Reconstruction of the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "hvHmo07eAfWA",
        "outputId": "80ce02ab-b520-476e-d20c-16f47aa50254"
      },
      "outputs": [],
      "source": [
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "reduced = (gamma.dot(dictionary)) + mean.T\n",
        "\n",
        "for ele in reduced:\n",
        "    if ele.any() < 0:\n",
        "        print(\"yes\")\n",
        "print(\"reconstruction patches shape:\", reduced.shape)\n",
        "red = reduced.reshape(res.shape)\n",
        "print('Final patch shape', red.shape)\n",
        "final_patches = vector_to_matrix_3d(reduced, -1,p_h,p_w)\n",
        "reduced_img = reconstruct_patches(final_patches, img.shape, 1)\n",
        "print(\"recon image shape:\", reduced_img.shape)\n",
        "# print(reduced)\n",
        "fin_recon_image = convert_to_uint8(reduced_img)\n",
        "plt.imsave('sigma_10_sparsity_30.jpg', fin_recon_image, cmap = 'gray')\n",
        "io.imshow(fin_recon_image, cmap = 'gray')\n",
        "io.show()\n",
        "print(reduced_img)\n",
        "print(\"Done....\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvrx0GBaAfWD"
      },
      "source": [
        "# If stride > 1, image contrast reduces, to improve the contrast apply Histogram matching with noisy image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0ebm3YNAfWE"
      },
      "source": [
        "## Function to implement the histogram matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xd6KDgSAfWF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def hist_match(source, template):\n",
        "    oldshape = source.shape\n",
        "    source = source.ravel()\n",
        "    template = template.ravel()\n",
        "\n",
        "    # get the set of unique pixel values and their corresponding indices and\n",
        "    # counts\n",
        "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n",
        "                                            return_counts=True)\n",
        "    t_values, t_counts = np.unique(template, return_counts=True)\n",
        "\n",
        "    # take the cumsum of the counts and normalize by the number of pixels to\n",
        "    # get the empirical cumulative distribution functions for the source and\n",
        "    # template images (maps pixel value --> quantile)\n",
        "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
        "    s_quantiles /= s_quantiles[-1]\n",
        "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
        "    t_quantiles /= t_quantiles[-1]\n",
        "\n",
        "    # interpolate linearly to find the pixel values in the template image\n",
        "    # that correspond most closely to the quantiles in the source image\n",
        "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
        "\n",
        "    return interp_t_values[bin_idx].reshape(oldshape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixH7uvs9AfWI"
      },
      "source": [
        "## Reading both the images and calling the matching function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G92c4azAfWI"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.misc import ascent\n",
        "import imageio as ios\n",
        "\n",
        "# Image Input\n",
        "image = cv2.imread(\"final_output/reduced_final_20.jpg\", 0)\n",
        "\n",
        "image1 = cv2.imread(\"girl_face_noise_20.jpg\", 0)\n",
        "\n",
        "x, y= image.shape\n",
        "\n",
        "x1, y1 = image1.shape\n",
        "\n",
        "\n",
        "moddedimage = np.zeros([x, y], dtype=np.uint8)\n",
        "\n",
        "# gray levels\n",
        "gray_levels = 256\n",
        "# row times column\n",
        "mn = x * y\n",
        "\n",
        "source = image\n",
        "template = image1\n",
        "matched = hist_match(source, template)\n",
        "\n",
        "\n",
        "def ecdf(x):\n",
        "    vals, counts = np.unique(x, return_counts=True)\n",
        "    ecdf = np.cumsum(counts).astype(np.float64)\n",
        "    ecdf /= ecdf[-1]\n",
        "    return vals, ecdf\n",
        "\n",
        "\n",
        "x1, y1 = ecdf(source.ravel())\n",
        "x2, y2 = ecdf(template.ravel())\n",
        "x3, y3 = ecdf(matched.ravel())\n",
        "\n",
        "\n",
        "plt.imshow(source, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Source')\n",
        "plt.show()\n",
        "plt.imshow(template, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Noisy Image')\n",
        "plt.show()\n",
        "plt.imshow(matched, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Denoised Image')\n",
        "plt.show()\n",
        "\n",
        "plt.imsave(\"final_output_match/matched_20.png\",matched)\n",
        "\n",
        "# image = cv2.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/matched.png\", 0)\n",
        "# cv2.imshow(\"image\", image)\n",
        "# cv2.waitKey(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "s9MyqRdOAfWS",
        "outputId": "d5e91602-d24a-47f9-e5dc-6d9c03202f3e"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# print(matched.dtype)\n",
        "\n",
        "# data = matched\n",
        "# data = data/(data.max())\n",
        "# data = 255 * data\n",
        "# img = data.astype(np.uint8)\n",
        "\n",
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "# count =0\n",
        "# for ele in matched:\n",
        "#     if ele.any() < 0:\n",
        "#         count += 1\n",
        "\n",
        "# print(count)\n",
        "\n",
        "original = cv2.imread(\"original.jpg\",0)\n",
        "# print(original.dtype)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(original, cmap ='gray')\n",
        "plt.show()\n",
        "\n",
        "image = cv2.imread(\"sigma_10_sparsity_30.jpg\", 0)\n",
        "contrast = convert_to_uint8(image)\n",
        "# print(original.dtype)\n",
        "plt.title(\"Reconstructed\")\n",
        "plt.imshow(contrast, cmap ='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# noisy = cv2.imread(\"Input Image with noise 10.jpg\",0)\n",
        "# plt.imshow(noisy, cmap = 'gray')\n",
        "# plt.title(\"Nosiy\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# contrast = img\n",
        "# plt.imshow(contrast, cmap = 'gray')\n",
        "# plt.show()\n",
        "\n",
        "i_h, i_w = original.shape\n",
        "pixels = i_h * i_w\n",
        "\n",
        "print(original.min())\n",
        "print(original.max())\n",
        "print(\"------------------\")\n",
        "print(contrast.min())\n",
        "print(contrast.max())\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2 )\n",
        "    print(\"Mse:\", mse)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    result_psnr = (20 * math.log10(PIXEL_MAX / math.sqrt(mse)))\n",
        "    return result_psnr\n",
        "\n",
        "d=psnr(original,contrast)\n",
        "print(\"PSNR between original and reconstructed image:\", d)\n",
        "\n",
        "# d= psnr(original, noisy)\n",
        "# print(\"PSNR between original and noisy image:\", d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH0CQhHEAfWZ"
      },
      "outputs": [],
      "source": [
        "# imagee = io.imread(\"F:/Internship/Data/brain_0% noise/brain_0_105.jpg\")\n",
        "# io.imshow(imagee)\n",
        "# io.show()\n",
        "# print(imagee.shape)\n",
        "\n",
        "image = cv2.imread('final_output/reduced_final_8.jpg', 0)\n",
        "print(image.shape)\n",
        "io.imshow(image)\n",
        "io.show()\n",
        "\n",
        "image = cv2.imread('girl_face_noise_20.jpg', 0)\n",
        "print(image.shape)\n",
        "io.imshow(image)\n",
        "io.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "ZBRpBbqdAfWk",
        "outputId": "c2cf59c8-cce0-4920-f22c-37518112e169"
      },
      "outputs": [],
      "source": [
        "from skimage.measure import compare_ssim as ssim\n",
        "\n",
        "def mse(x, y):\n",
        "    return np.linalg.norm(x - y)\n",
        "  \n",
        "image = cv2.imread(\"input Image.jpg\", 0)\n",
        "recon_image = cv2.imread(\"sigma_10_sparsity_30.jpg\",0)\n",
        "\n",
        "print(recon_image.shape)\n",
        "print(image.shape)\n",
        "\n",
        "mse_noise = mse(image, recon_image)\n",
        "ssim_noise = ssim(image, recon_image,\n",
        "                  data_range=recon_image.max() - recon_image.min())\n",
        "\n",
        "print(mse_noise)\n",
        "print(ssim_noise)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "K-SVD_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
