{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn6uRdPbZyvm"
      },
      "source": [
        "# Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP0keEHTZyvq"
      },
      "outputs": [],
      "source": [
        "import numbers\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "import numpy as np\n",
        "from skimage import io, util\n",
        "import sklearn.feature_extraction as sk\n",
        "# from ksvd import ApproximateKSVD\n",
        "import cv2\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg\n",
        "from math import sqrt\n",
        "import scipy\n",
        "import math\n",
        "import pywt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzaEFJTtZyvx"
      },
      "source": [
        "# KSVD CLASS \n",
        "\n",
        "## Ksvd class for training the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZu0t9EFZyvz"
      },
      "outputs": [],
      "source": [
        "# coding:utf-8\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from sklearn.linear_model import orthogonal_mp_gram\n",
        "\n",
        "\n",
        "class ApproximateKSVD(object):\n",
        "    def __init__(self, n_components, dictionary = None, max_iter=20, tol=1e-6,\n",
        "                 transform_n_nonzero_coefs = None, l=0.1, n = 1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_components:\n",
        "            Number of dictionary elements\n",
        "\n",
        "        max_iter:\n",
        "            Maximum number of iterations\n",
        "\n",
        "        tol:\n",
        "            tolerance for error\n",
        "\n",
        "        transform_n_nonzero_coefs:\n",
        "            Number of nonzero coefficients to target\n",
        "        \"\"\"\n",
        "        self.components_ = None\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.n_components = n_components\n",
        "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
        "        self.l = l\n",
        "        self.n = n\n",
        "        self.D = dictionary\n",
        "\n",
        "    def _update_dict(self, X, D, gamma):\n",
        "        for j in range(self.n_components):\n",
        "            I = gamma[:, j] > 0\n",
        "            if np.sum(I) == 0:\n",
        "                continue\n",
        "\n",
        "            D[j, :] = 0\n",
        "            g = gamma[I, j].T\n",
        "#             print(gamma.shape)\n",
        "#             print(X.shape)\n",
        "#             print(len(I))\n",
        "            r = X[I, :] - gamma[I, :].dot(D)\n",
        "            d = r.T.dot(g)\n",
        "            d /= np.linalg.norm(d)\n",
        "            g = r.dot(d)\n",
        "            D[j, :] = d\n",
        "            gamma[I, j] = g.T\n",
        "        return D, gamma\n",
        "\n",
        "#     def _initialize(self, X):\n",
        "#         if min(X.shape) < self.n_components:\n",
        "#             D = np.random.randn(self.n_components, X.shape[1])\n",
        "# #             print(\"Dictionary:\", D.shape)\n",
        "#         else:\n",
        "#             u, s, vt = sp.sparse.linalg.svds(X, k=self.n_components)\n",
        "#             D = np.dot(np.diag(s), vt)\n",
        "#         D /= np.linalg.norm(D, axis=1)[:, np.newaxis]\n",
        "#         return D\n",
        "\n",
        "    # def soft_thresh(self, x, s):\n",
        "    #   return np.sign(x) * np.maximum(np.abs(x) - s, 0.)  # shrinkage operation\n",
        "    \n",
        "    def adalam(self, xold, lamold, gam):\n",
        "      \n",
        "#       print(\"Size of xold\", len(xold))\n",
        "#       print(\"Size of lamold\", len(lamold))\n",
        "#       print(\"Size of gam\", gam)\n",
        "      \n",
        "      lamold = np.where((abs(xold) - lamold*gam) < 0, lamold - abs(xold)/gam, 0)\n",
        "#       if(abs(xold).all() <= lamold*gam):\n",
        "#         return (lamold - abs(xold)/gam)\n",
        "#       else:\n",
        "#         return 0\n",
        "      return lamold\n",
        "    \n",
        "    \n",
        "    def fista(self, I, Phi, lambdav, n, max_iterations=150, display=False):\n",
        "        \n",
        "        def proxOp(x,t):\n",
        "            \"\"\" L1 Proximal Operator \"\"\" \n",
        "            return np.fmax(x-t, 0) + np.fmin(x+t, 0)\n",
        "        \n",
        "        I = I.T\n",
        "        Phi = Phi.T\n",
        "        print(\"Phi shape\", Phi.shape)\n",
        "        print(\"l value\", lambdav)\n",
        "        x = np.zeros((Phi.shape[1], I.shape[1]))\n",
        "        Q = Phi.T.dot(Phi)\n",
        "        c = -2*Phi.T.dot(I)\n",
        "        print(\"n value\", n)\n",
        "        print(max_iterations)\n",
        "\n",
        "        L = scipy.sparse.linalg.eigsh(2*Q, 1, which='LM')[0]\n",
        "        invL = 1/float(L)\n",
        "        it = 0\n",
        "        y = x\n",
        "        t = 1\n",
        "        gamma_list = []\n",
        "#         err = []\n",
        "\n",
        "        for i in range(max_iterations):\n",
        "            g = 2*Q.dot(y) + c\n",
        "            x_prox = y - (invL * g)\n",
        "            t_prox = invL*lambdav\n",
        "            x2 = proxOp(y-invL*g,invL*lambdav)\n",
        "            t2 = (1+math.sqrt(1+4*(t**2)))/2.0\n",
        "            y = x2 + ((t-1)/t2)*(x2-x)\n",
        "            j = 0\n",
        "  \n",
        "            lambdav = self.adalam(x_prox, lambdav, n)\n",
        "            x = x2\n",
        "            t = t2\n",
        "#             ee = np.linalg.norm(I.T - x2.T.dot(Phi.T))\n",
        "#             err.append(ee)\n",
        "#             print(\"||Y - DX||2 for iteration {0} is: \".format(i+1), ee)\n",
        "\n",
        "           \n",
        "            if(i == 25 or i == 50 or i == 100):\n",
        "              gamma_list.append(x2)\n",
        "\n",
        "        print(\"Lambdav value after updation:\", lambdav)\n",
        "        print(\"Lambdav size:\", len(lambdav))\n",
        "\n",
        "        it += 1\n",
        "#         plt.plot(err)\n",
        "#         plt.show()\n",
        "        print(\"Iteration {0} done.\".format(it))\n",
        "        \n",
        "        for j in range(3):\n",
        "          gamma_list[j] = gamma_list[j].T\n",
        "\n",
        "        return x2, gamma_list\n",
        "\n",
        "\n",
        "    def fit(self, X, l = 0.1, n = 1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: shape = [n_samples, n_features]\n",
        "        \"\"\"\n",
        "        # print(X)\n",
        "        # print(X.shape[1])\n",
        "        y = []\n",
        "        gamma_list = []\n",
        "        D = self.D\n",
        "        l = self.l\n",
        "        n = self.n\n",
        "        transform_n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
        "        for i in range(self.max_iter):\n",
        "            dict_list = []\n",
        "            gamma, gamma_list = self.fista(X, D, l, n, max_iterations = 150)\n",
        "            gamma = gamma.T\n",
        "            \n",
        "            e = np.linalg.norm(X - gamma.dot(D))\n",
        "            y.append(e)\n",
        "            print(\"||Y - DX||2 for iteration {0} is: \".format(i+1), e)\n",
        "            if e < self.tol:\n",
        "                break\n",
        "            \n",
        "            print(\"gamma shape\", gamma.shape)\n",
        "            print(\"gama list shape\", gamma_list[0].shape)\n",
        "            print(\"D shape\", D.shape)\n",
        "            \n",
        "            \n",
        "            D, gamma = self._update_dict(X, D, gamma)\n",
        "\n",
        "\n",
        "        plt.plot(y)\n",
        "        with open(\"sigma_10_0.3_70.txt\", \"wb\") as fp:   #Pickling\n",
        "          pickle.dump(y, fp)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        return D\n",
        "\n",
        "    def transform(self, X, dictionary, l = 0.1, n = 1):\n",
        "        gamma_list = []\n",
        "        gamma, gamma_list = self.fista(X, dictionary, l,  n, max_iterations = 150)\n",
        "        return gamma, gamma_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zvx1UypZyv3"
      },
      "source": [
        "# Function to compute the number of patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqu8kfFvZyv4"
      },
      "outputs": [],
      "source": [
        "def _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches=None):\n",
        "\n",
        "    n_h = (i_h - p_h) // step + 1\n",
        "    n_w = (i_w - p_w) // step + 1\n",
        "    all_patches = n_h * n_w\n",
        "\n",
        "    return all_patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxghZL6Zyv8"
      },
      "source": [
        "# Function to extract the patches from Input Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OJvcM68Zyv9"
      },
      "outputs": [],
      "source": [
        "def _extracting(arr, patch_shape=8, extraction_step=1):\n",
        "\n",
        "    arr_ndim = arr.ndim\n",
        "\n",
        "    if isinstance(patch_shape, numbers.Number):\n",
        "        patch_shape = tuple([patch_shape] * arr_ndim)\n",
        "    if isinstance(extraction_step, numbers.Number):\n",
        "        extraction_step = tuple([extraction_step] * arr_ndim)\n",
        "\n",
        "    patch_strides = arr.strides\n",
        "\n",
        "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
        "    indexing_strides = arr[slices].strides\n",
        "\n",
        "    patch_indices_shape = ((np.array(arr.shape) - np.array(patch_shape)) //\n",
        "                           np.array(extraction_step)) + 1\n",
        "\n",
        "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
        "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
        "\n",
        "    patches = as_strided(arr, shape=shape, strides=strides)\n",
        "\n",
        "    # patches = patches.reshape([-1] + list(patch_shape))\n",
        "\n",
        "    return patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fENPgygSZywC"
      },
      "source": [
        "# Function to call the extraction step and reshaping the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzpwrnAXZywD"
      },
      "outputs": [],
      "source": [
        "def extract_patches(image, patch_size, step, max_patches=None, random_state=None):\n",
        "\n",
        "    i_h, i_w = image.shape[:2]\n",
        "    p_h, p_w = patch_size\n",
        "\n",
        "    # image = check_array(image, allow_nd=True)\n",
        "    image = image.reshape((i_h, i_w, -1))\n",
        "    n_colors = image.shape[-1]\n",
        "\n",
        "    extracted_patches = _extracting(image, patch_shape=(p_h, p_w, n_colors), extraction_step=step) # above function call\n",
        "    n_patches = _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches)\n",
        "    # print n_patches\n",
        "    # if max_patches:\n",
        "    #     rng = check_random_state(random_state)\n",
        "    #     i_s = rng.randint(i_h - p_h + step, size=n_patches)\n",
        "    #     j_s = rng.randint(i_w - p_w + step, size=n_patches)\n",
        "    #     patches = extracted_patches[i_s, j_s, 0]\n",
        "    # else:\n",
        "    patches = extracted_patches\n",
        "\n",
        "    patches = patches.reshape(-1, p_h, p_w, n_colors)\n",
        "    # print patches.shape\n",
        "    # remove the color dimension if useless\n",
        "    if patches.shape[-1] == 1:\n",
        "        return patches.reshape(n_patches, p_h, p_w)\n",
        "    else:\n",
        "        return patches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBe3gmaeZywG"
      },
      "source": [
        "# Funtion for Reconstruction of the image from the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUg1gZXFZywI"
      },
      "outputs": [],
      "source": [
        "def reconstruct_patches(patches, image_size, step):\n",
        "\n",
        "    i_h, i_w = image_size[:2]\n",
        "    p_h, p_w = patches.shape[1:3]\n",
        "    img = np.zeros(image_size)\n",
        "    # compute the dimensions of the patches array\n",
        "    n_h = int((i_h - p_h) / step + 1)\n",
        "    n_w = int((i_w - p_w) / step + 1)\n",
        "    for p, (i, j) in zip(patches, product(range(n_h), range(n_w))):\n",
        "        img[i * step:i * step + p_h, j * step:j * step + p_w] += p\n",
        "\n",
        "    for i in range(i_h):\n",
        "        for j in range(i_w):\n",
        "            img[i, j] /= float(min(i + step, p_h, i_h - i) *\n",
        "                               min(j + step, p_w, i_w - j))\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNeRByRGZywP"
      },
      "source": [
        "# If the input image is not noisy, function to add noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhPFQVovZywR",
        "outputId": "69ee016f-2117-457f-bf1f-bfd10f2bef62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding Noise\n",
            "Done with noise\n"
          ]
        }
      ],
      "source": [
        "img = util.img_as_float(io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/input/Lenna.jpg\"))\n",
        "print(\"Adding Noise\")\n",
        "img_with_noise = util.random_noise(img, seed=1)\n",
        "io.imsave(\"noise.png\", img_with_noise)\n",
        "print(\"Done with noise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXbphEqUZywa"
      },
      "source": [
        "# Loading of Image and Extracting patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jKSQnDKqZywc",
        "outputId": "5c6cbe40-1aa5-4473-de84-328e6a8e3995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patches shape:  (36540, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "img = util.img_as_float(cv2.imread(\"girl_face_noise_15.jpg\", 0))\n",
        "# image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/Prova.jpg\")\n",
        "\n",
        "res = extract_patches(img, (8, 8), 1)\n",
        "# width, height, col= res.shape\n",
        "# print(\"initial Image shape\", img.shape)\n",
        "print(\"Patches shape: \", res.shape)\n",
        "num_patch, p_h, p_w = res.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbH4B3fzZywg"
      },
      "source": [
        "# Functions for converting 2d or 3d matrix to vector and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7KX6tKjZywh"
      },
      "outputs": [],
      "source": [
        "def matrix_to_vector(matrix, patch_size):\n",
        "    \n",
        "    list = np.split(matrix.reshape(-1,patch_size),matrix.shape[0])\n",
        "    \n",
        "    list1 = []\n",
        "    \n",
        "    \n",
        "    for arr in list:\n",
        "        bb = arr.flatten('F').reshape(patch_size**2,1)\n",
        "        list1.append(bb)\n",
        "\n",
        "    array = np.array(list1).squeeze()\n",
        "    \n",
        "    return array\n",
        "\n",
        "\n",
        "def vector_to_matrix_2d(vector,h,w):\n",
        "    \n",
        "    ab = np.reshape(vector,(h,w))\n",
        "    return ab.T\n",
        "\n",
        "def vector_to_matrix_3d(vector, h, w, col):\n",
        "\n",
        "    ab = np.reshape(vector,(h,w,col))\n",
        "#     print(ab.T)\n",
        "    return ab.transpose(0,2,1)\n",
        "\n",
        "\n",
        "# aa= np.array(range(27)).reshape(3,3,3)\n",
        "# print(aa)\n",
        "# print(\"------------------------\")\n",
        "\n",
        "# bb = matrix_to_vector(aa, 3)\n",
        "# print(bb)\n",
        "\n",
        "# ab = vector_to_matrix_3d(array, -1,3,3)\n",
        "# print(ab)\n",
        "\n",
        "# ba = vector_to_matrix_2d(bb[0], 3, 3)\n",
        "# print(ba)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY2dajc9Zywl"
      },
      "source": [
        "# Pre-Processing step: Removing the mean from each value of the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6qFPBkd0Zywm",
        "outputId": "b6453a0c-fe36-4eb8-ec14-f0c0bdb293ce"
      },
      "outputs": [],
      "source": [
        "imag = res[1]\n",
        "print(imag.shape)\n",
        "io.imshow(imag, cmap= 'gray')\n",
        "io.show()\n",
        "\n",
        "signals = matrix_to_vector(res, p_w)\n",
        "\n",
        "num_patches, patch_size = signals.shape\n",
        "\n",
        "print(\"Signals final shape\", signals.shape)\n",
        "mean = np.mean(signals, axis=0)[:, np.newaxis]\n",
        "print(\"Mean value shape: \", mean.shape)\n",
        "\n",
        "mean1 = vector_to_matrix_2d(mean,p_h,p_w)\n",
        "io.imshow(mean1, cmap = 'gray')\n",
        "io.show()\n",
        "\n",
        "signals = (signals.T - mean).T\n",
        "\n",
        "signals1 = vector_to_matrix_2d(signals[1], p_h, p_w)\n",
        "io.imshow(signals1, cmap = 'gray')\n",
        "io.show()\n",
        "\n",
        "signal_final = signals1 + mean1\n",
        "\n",
        "io.imshow(signal_final,  cmap= 'gray')\n",
        "io.show()\n",
        "\n",
        "if signal_final.all() == imag.all():\n",
        "    print(\"True\")\n",
        "else:\n",
        "    print(\"false\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-CAk7DZywu"
      },
      "source": [
        "# Applying KSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OGqU32mpZyww",
        "outputId": "f47f9e9f-b3ee-40bd-c7f9-84d90802da08"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "\n",
        "dict_list = []\n",
        "gamma_list = []\n",
        "\n",
        "bdict = sio.loadmat('dictionary_intialize.mat')\n",
        "for rel in bdict:\n",
        "   if rel == 'dictionary':\n",
        "      diction = bdict['dictionary']\n",
        "\n",
        "print(diction.shape)\n",
        "\n",
        "lambdav = np.ones((diction.shape[0], signals.shape[0]), dtype = int)\n",
        "\n",
        "print(\"Applying L1-DL\")\n",
        "aksvd = ApproximateKSVD(n_components=128, dictionary = diction, l = 0.3*lambdav, n = 70)\n",
        "dictionary = aksvd.fit(signals)\n",
        "print(\"Done with learning\")\n",
        "# np.savetxt(\"test.txt\", dictionary)\n",
        "gamma, gamma_list = aksvd.transform(signals, dictionary, l = 0.3*lambdav, n = 70)\n",
        "print(\"Found gamma\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Applying KSVD with Dictionary Initialization (Comment the above cell and choose this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Applying L1-DL\")\n",
        "aksvd = ApproximateKSVD(n_components=128, l = 0.2)\n",
        "dictionary = aksvd.fit(signals).components_\n",
        "print(\"Done with learning\")\n",
        "# np.savetxt(\"test.txt\", dictionary)\n",
        "gamma = aksvd.transform(signals, l = 0.2)\n",
        "print(\"Found gamma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Nz53xvyNtd00",
        "outputId": "25679682-c047-4c48-cc77-5619c760c0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93.64916871921183\n"
          ]
        }
      ],
      "source": [
        "from numpy import array\n",
        "from numpy import count_nonzero\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "sparsity = 1.0 - ( count_nonzero(gamma) / float(gamma.size) )\n",
        "print(sparsity*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "pqipequ3PN21",
        "outputId": "a9bbc07c-3560-4d74-c89a-ed812aa7c91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "dictionary_25\n",
            "dictionary_50\n",
            "dictionary_100\n"
          ]
        }
      ],
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "dict_25, gamma_25 = aksvd._update_dict(signals, dictionary, gamma_list[0])\n",
        "dict_50, gamma_50 = aksvd._update_dict(signals, dictionary, gamma_list[1])\n",
        "dict_100, gamma_100 = aksvd._update_dict(signals, dictionary, gamma_list[2])\n",
        "\n",
        "dict_list = [dict_25, dict_50, dict_100]\n",
        "print(len(dict_list))\n",
        "\n",
        "adict = {}\n",
        "adict['dictionary_25'] = dict_list[0]\n",
        "adict['dictionary_50'] = dict_list[1]\n",
        "adict['dictionary_100'] = dict_list[2]\n",
        "\n",
        "sio.savemat('diff_dict.mat', adict)\n",
        "\n",
        "for rel in adict:\n",
        "  print(rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isG-ciGt499K"
      },
      "outputs": [],
      "source": [
        "# import scipy.io as sio\n",
        "\n",
        "# adict = {}\n",
        "# adict['dictionary_25'] = dict_list[0]\n",
        "# adict['dictionary_50'] = dict_list[1]\n",
        "# adict['dictionary_100'] = dict_list[2]\n",
        "\n",
        "# sio.savemat('diff_dict.mat', adict)\n",
        "\n",
        "# for rel in adict:\n",
        "#   print(rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "uiMU98x7_Hbc",
        "outputId": "dcb5c9b7-8f89-423e-904b-170220e8dfb7"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "agamma = {}\n",
        "agamma['gamma_25'] = gamma_list[0]\n",
        "agamma['gamma_50'] = gamma_list[1]\n",
        "agamma['gamma_100'] = gamma_list[2]\n",
        "\n",
        "sio.savemat('diff_gamma.mat', agamma)\n",
        "\n",
        "print(gamma_list[0].shape)\n",
        "\n",
        "for rel in agamma:\n",
        "  print(rel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Saving Dicitonary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "vVKQsYAtZyw0",
        "outputId": "188c8b01-c948-4c8a-ec06-11fa908c7f46"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "\n",
        "adict = {}\n",
        "adict['dictionary'] = dictionary\n",
        "\n",
        "sio.savemat('sigma_20_lambda_0.5_150_iterations_n = 120_patch_size_{0}x{1}.mat'.format(p_h,p_w), adict)\n",
        "\n",
        "bdict = sio.loadmat('sigma_20_lambda_0.5_150_iterations_n = 120_patch_size_{0}x{1}.mat'.format(p_h,p_w))\n",
        "for rel in bdict:\n",
        "    print(rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xWscgUKaZyxE",
        "outputId": "feb75c88-a974-4459-9f69-64b1cabfe41d"
      },
      "outputs": [],
      "source": [
        "print(dictionary[1].shape)\n",
        "element = dictionary[1] + mean.T\n",
        "print(element.shape)\n",
        "element_1 = vector_to_matrix_2d(element, p_h, p_w)\n",
        "io.imshow(element_1, cmap = 'gray')\n",
        "io.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmvETcpzZyxO"
      },
      "source": [
        "# Function for extracting images (patches) from Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYTmlkteZyxQ"
      },
      "outputs": [],
      "source": [
        "from tempfile import TemporaryFile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = os.path.join(folder, filename)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSvIVqYTZyxY"
      },
      "source": [
        "# Function to load the dictionary and convert to patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "JVPpj3zuZyxa",
        "outputId": "54679238-9d87-4aa6-b5d5-b389ecb950be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 128)\n"
          ]
        }
      ],
      "source": [
        "dictionary1 = dictionary.T + mean\n",
        "\n",
        "file = dictionary1\n",
        "print(file.shape)\n",
        "\n",
        "K = file.shape[1]\n",
        "# file1 = file.T\n",
        "# print(file1.shape)\n",
        "\n",
        "i = 0\n",
        "k = 0\n",
        "a = np.zeros((8, 16))\n",
        "b = np.zeros((8, 8))\n",
        "result = []\n",
        "#\n",
        "while k < file.shape[1]:\n",
        "    arr = file[:,k]\n",
        "    # a, b = split_array(arr)\n",
        "    a = np.reshape(arr, (-1, 8))\n",
        "    # b = np.reshape(b, (-1, 8))\n",
        "\n",
        "    result.append(a)\n",
        "\n",
        "    k += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkWEs1s-Zyxg"
      },
      "source": [
        "# Save each extracted patch as an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZBUalBhZyxj",
        "outputId": "ac5136ba-6156-4025-9ad1-4ca7c976e707"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "\n",
        "for i in range(result.__len__()):\n",
        "    path = 'jup_images'\n",
        "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), result[i])\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMcJJaCZyxn"
      },
      "source": [
        "# Load the images and concatenate them to save as a single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5L8jr11Zyxp"
      },
      "outputs": [],
      "source": [
        "image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/img_0.jpg\")\n",
        "\n",
        "images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/\")\n",
        "\n",
        "BLUE = [0, 0, 0]\n",
        "final = []\n",
        "\n",
        "for img in images:\n",
        "    img = cv2.imread(img)\n",
        "    de_img= cv2.copyMakeBorder(img,1,1,1,1,cv2.BORDER_CONSTANT,value= BLUE)\n",
        "    final.append(de_img)\n",
        "    \n",
        "count = 0\n",
        "\n",
        "for i in range(final.__len__()):\n",
        "    path = 'jup_images_final'\n",
        "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), final[i])\n",
        "    count += 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "final_images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images_final/\")\n",
        "\n",
        "new_im = Image.new('RGB', (80, 160))\n",
        "\n",
        "x_offset = 0\n",
        "y_offset = 0\n",
        "count = 0\n",
        "\n",
        "i = 0\n",
        "k = 0\n",
        "j = 0\n",
        "\n",
        "# for img in images:\n",
        "#     imga = io.imread(img)\n",
        "#     count += 1\n",
        "#     print(count)\n",
        "#     io.imshow(imga)\n",
        "#     io.show()\n",
        "\n",
        "\n",
        "while j < 16:\n",
        "    while i < 8:\n",
        "        # fin = open(image)  # open the file\n",
        "        img = Image.open(final_images[k])\n",
        "        ext_img = img\n",
        "        new_im.paste(ext_img, (x_offset, y_offset))\n",
        "        x_offset += img.size[0]\n",
        "        i += 1\n",
        "        print('yes x_{0}'.format(i))\n",
        "        print('yes k_{0}'.format(k))\n",
        "        print(\"Offset x: \", x_offset)\n",
        "        k += 1\n",
        "    i = 0\n",
        "    y_offset += img.size[1]\n",
        "    x_offset = 0\n",
        "    j += 1\n",
        "    print('yes y_{0}'.format(j))\n",
        "    print(\"Y-offset\", y_offset)\n",
        "\n",
        "print(\"X:\", x_offset)\n",
        "print(\"Y:\", y_offset)\n",
        "\n",
        "new_im.save('test2.jpg')\n",
        "\n",
        "imagee = io.imread(\"test2.jpg\")\n",
        "io.imshow(imagee)\n",
        "io.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM18uROnZyxu"
      },
      "source": [
        "# Reconstruction of the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "4xVdLPvVZyxv",
        "outputId": "595e8dec-1064-46a1-a284-94839fc6906f"
      },
      "outputs": [],
      "source": [
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "reduced = (gamma.T.dot(dictionary)) + mean.T\n",
        "\n",
        "for ele in reduced:\n",
        "    if ele.any() < 0:\n",
        "        print(\"yes\")\n",
        "print(\"reconstruction patches shape:\", reduced.shape)\n",
        "red = reduced.reshape(res.shape)\n",
        "print('Final patch shape', red.shape)\n",
        "final_patches = vector_to_matrix_3d(reduced, -1,p_h,p_w)\n",
        "reduced_img = reconstruct_patches(final_patches, img.shape, 1)\n",
        "print(\"recon image shape:\", reduced_img.shape)\n",
        "# print(reduced)\n",
        "fin_recon_image = convert_to_uint8(reduced_img)\n",
        "cv2.imwrite('0.1_150_n = 40_sigma_5_l1.jpg', fin_recon_image)\n",
        "io.imshow(fin_recon_image, cmap = 'gray')\n",
        "io.show()\n",
        "print(fin_recon_image)\n",
        "print(\"Done....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1M2-ulDh_xXA",
        "outputId": "817d80b2-4ccc-4d00-ea2e-176a81a0e999"
      },
      "outputs": [],
      "source": [
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "reduced_25 = (gamma_list[0].dot(dict_list[0])) + mean.T\n",
        "reduced_50 = (gamma_list[1].dot(dict_list[1])) + mean.T\n",
        "reduced_100 = (gamma_list[2].dot(dict_list[2])) + mean.T\n",
        "\n",
        "\n",
        "for ele in reduced:\n",
        "    if ele.any() < 0:\n",
        "        print(\"yes\")\n",
        "print(\"reconstruction patches shape:\", reduced.shape)\n",
        "\n",
        "red_25 = reduced_25.reshape(res.shape)\n",
        "red_50 = reduced_50.reshape(res.shape)\n",
        "red_100 = reduced_100.reshape(res.shape)\n",
        "\n",
        "print('Final patch shape', red_25.shape)\n",
        "\n",
        "final_patches_25 = vector_to_matrix_3d(reduced_25, -1,p_h,p_w)\n",
        "final_patches_50 = vector_to_matrix_3d(reduced_50, -1,p_h,p_w)\n",
        "final_patches_100 = vector_to_matrix_3d(reduced_100, -1,p_h,p_w)\n",
        "\n",
        "reduced_img_25 = reconstruct_patches(final_patches_25, img.shape, 1)\n",
        "reduced_img_50 = reconstruct_patches(final_patches_50, img.shape, 1)\n",
        "reduced_img_100 = reconstruct_patches(final_patches_100, img.shape, 1)\n",
        "\n",
        "print(\"recon image shape:\", reduced_img_25.shape)\n",
        "# print(reduced)\n",
        "fin_recon_image_25 = convert_to_uint8(reduced_img_25)\n",
        "fin_recon_image_50 = convert_to_uint8(reduced_img_50)\n",
        "fin_recon_image_100 = convert_to_uint8(reduced_img_100)\n",
        "\n",
        "print(fin_recon_image_25)\n",
        "# io.imsave(\"25 iterations\", fin_recon_image_25)\n",
        "\n",
        "cv2.imwrite('25 iterations.jpg', fin_recon_image_25)\n",
        "cv2.imwrite('50 iterations.jpg', fin_recon_image_50)\n",
        "cv2.imwrite('100 iterations.jpg', fin_recon_image_100)\n",
        "\n",
        "io.imshow(fin_recon_image_25, cmap = 'gray')\n",
        "io.show()\n",
        "io.imshow(fin_recon_image_50, cmap = 'gray')\n",
        "io.show()\n",
        "io.imshow(fin_recon_image_100, cmap = 'gray')\n",
        "io.show()\n",
        "# print(fin_recon_image)\n",
        "print(\"Done....\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cozqn6NlZyx0"
      },
      "source": [
        "# If stride > 1, image contrast reduces, to improve the contrast apply Histogram matching with noisy image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec6WOEeAZyx2"
      },
      "source": [
        "## Function to implement the histogram matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my2pCTP4Zyx3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def hist_match(source, template):\n",
        "    oldshape = source.shape\n",
        "    source = source.ravel()\n",
        "    template = template.ravel()\n",
        "\n",
        "    # get the set of unique pixel values and their corresponding indices and\n",
        "    # counts\n",
        "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n",
        "                                            return_counts=True)\n",
        "    t_values, t_counts = np.unique(template, return_counts=True)\n",
        "\n",
        "    # take the cumsum of the counts and normalize by the number of pixels to\n",
        "    # get the empirical cumulative distribution functions for the source and\n",
        "    # template images (maps pixel value --> quantile)\n",
        "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
        "    s_quantiles /= s_quantiles[-1]\n",
        "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
        "    t_quantiles /= t_quantiles[-1]\n",
        "\n",
        "    # interpolate linearly to find the pixel values in the template image\n",
        "    # that correspond most closely to the quantiles in the source image\n",
        "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
        "\n",
        "    return interp_t_values[bin_idx].reshape(oldshape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o49akY2VZyx9"
      },
      "source": [
        "## Reading both the images and calling the matching function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aein07_aZyyA"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.misc import ascent\n",
        "import imageio as ios\n",
        "\n",
        "# Image Input\n",
        "image = cv2.imread(\"reduced_final_0.2_l1.jpg\", 0)\n",
        "\n",
        "image1 = cv2.imread(\"girl_face_noise_15.jpg\", 0)\n",
        "\n",
        "x, y= image.shape\n",
        "\n",
        "x1, y1 = image1.shape\n",
        "\n",
        "\n",
        "moddedimage = np.zeros([x, y], dtype=np.uint8)\n",
        "\n",
        "# gray levels\n",
        "gray_levels = 256\n",
        "# row times column\n",
        "mn = x * y\n",
        "\n",
        "source = image\n",
        "template = image1\n",
        "matched = hist_match(source, template)\n",
        "\n",
        "\n",
        "def ecdf(x):\n",
        "    vals, counts = np.unique(x, return_counts=True)\n",
        "    ecdf = np.cumsum(counts).astype(np.float64)\n",
        "    ecdf /= ecdf[-1]\n",
        "    return vals, ecdf\n",
        "\n",
        "\n",
        "x1, y1 = ecdf(source.ravel())\n",
        "x2, y2 = ecdf(template.ravel())\n",
        "x3, y3 = ecdf(matched.ravel())\n",
        "\n",
        "\n",
        "plt.imshow(source, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Source')\n",
        "plt.show()\n",
        "plt.imshow(template, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Noisy Image')\n",
        "plt.show()\n",
        "plt.imshow(matched, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Denoised Image')\n",
        "plt.show()\n",
        "\n",
        "cv2.imwrite(\"reduced_final_0.2_l1_hist.jpg\",matched)\n",
        "\n",
        "# image = cv2.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/matched.png\", 0)\n",
        "# cv2.imshow(\"image\", image)\n",
        "# cv2.waitKey(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Misc Codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PwO5_FffZyyH",
        "outputId": "b4bb2f91-a7dc-43f3-ca95-bc01648ce15f"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# print(matched.dtype)\n",
        "\n",
        "# data = matched\n",
        "# data = data/(data.max())\n",
        "# data = 255 * data\n",
        "# img = data.astype(np.uint8)\n",
        "\n",
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "# count =0\n",
        "# for ele in matched:\n",
        "#     if ele.any() < 0:\n",
        "#         count += 1\n",
        "\n",
        "# print(count)\n",
        "\n",
        "original = cv2.imread(\"image.jpg\",0)\n",
        "# print(original.dtype)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(original, cmap ='gray')\n",
        "plt.show()\n",
        "\n",
        "image = fin_recon_image\n",
        "# contrast = convert_to_uint8(image)\n",
        "# print(original.dtype)\n",
        "plt.title(\"Reconstructed\")\n",
        "plt.imshow(image, cmap ='gray')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "noisy = fin_recon_image_25\n",
        "plt.imshow(noisy, cmap = 'gray')\n",
        "plt.title(\"25\")\n",
        "plt.show()\n",
        "\n",
        "noisy1 = fin_recon_image_50\n",
        "plt.imshow(noisy, cmap = 'gray')\n",
        "plt.title(\"50\")\n",
        "plt.show()\n",
        "\n",
        "noisy2 = fin_recon_image_100\n",
        "plt.imshow(noisy, cmap = 'gray')\n",
        "plt.title(\"100\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# contrast = img\n",
        "# plt.imshow(contrast, cmap = 'gray')\n",
        "# plt.show()\n",
        "\n",
        "i_h, i_w = original.shape\n",
        "pixels = i_h * i_w\n",
        "\n",
        "print(original.min())\n",
        "print(original.max())\n",
        "print(\"------------------\")\n",
        "print(image.min())\n",
        "print(image.max())\n",
        "\n",
        "def psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2 )\n",
        "    print(\"Mse:\", mse)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    PIXEL_MAX = 255.0\n",
        "    result_psnr = (20 * math.log10(PIXEL_MAX / math.sqrt(mse)))\n",
        "    return result_psnr\n",
        "\n",
        "  \n",
        "d= psnr(original, noisy)\n",
        "print(\"PSNR between original and 25 iterations\", d)\n",
        "\n",
        "d= psnr(original, noisy1)\n",
        "print(\"PSNR between original and 50 iterations\", d)\n",
        "\n",
        "d= psnr(original, noisy2)\n",
        "print(\"PSNR between original and 100 iterations\", d)\n",
        "\n",
        "d=psnr(original,image)\n",
        "print(\"PSNR between original and 150 iterations:\", d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOOiN4a-ZyyP"
      },
      "outputs": [],
      "source": [
        "# imagee = io.imread(\"F:/Internship/Data/brain_0% noise/brain_0_105.jpg\")\n",
        "# io.imshow(imagee)\n",
        "# io.show()\n",
        "# print(imagee.shape)\n",
        "\n",
        "def convert_to_uint8(image_in):\n",
        "    temp_image = np.float64(np.copy(image_in))\n",
        "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "\n",
        "    return temp_image.astype(np.uint8)\n",
        "\n",
        "\n",
        "image = cv2.imread('reduced_final_11_l1.jpg', 0)\n",
        "print(image.shape)\n",
        "io.imshow(image)\n",
        "io.show()\n",
        "\n",
        "contrast = convert_to_uint8(image)\n",
        "# print(original.dtype)\n",
        "plt.title(\"Reconstructed\")\n",
        "plt.imshow(contrast, cmap ='gray')\n",
        "plt.show()\n",
        "# image = cv2.imread('girl_face_noise_20.jpg', 0)\n",
        "# print(image.shape)\n",
        "# io.imshow(image)\n",
        "# io.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "BCyv_uccZyyT",
        "outputId": "595a63f1-ab4c-4abd-fad3-146b95f80580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 iterations mse 46704.45015199301\n",
            "25 iterations ssim 0.8403112934716999\n",
            "50 iterations mse 44782.57973810799\n",
            "50 iterations ssim 0.865347060326885\n",
            "100 iterations mse 45087.24986068678\n",
            "100 iterations ssim 0.8663812663163026\n",
            "150 iterations mse 45155.59893302269\n",
            "150 iterations ssim 0.8584535595934333\n"
          ]
        }
      ],
      "source": [
        "from skimage.measure import compare_ssim as ssim\n",
        "\n",
        "def mse(x, y):\n",
        "    return np.linalg.norm(x - y)\n",
        "  \n",
        "image = cv2.imread(\"image.jpg\", 0)\n",
        "recon_image_25 = cv2.imread(\"25 iterations.jpg\",0)\n",
        "recon_image_50 = cv2.imread(\"50 iterations.jpg\",0)\n",
        "recon_image_100 = cv2.imread(\"100 iterations.jpg\",0)\n",
        "recon_image_150 = cv2.imread(\"0.1_150_n = 40_sigma_5_l1.jpg\",0)\n",
        "\n",
        "\n",
        "# print(recon_image.shape)\n",
        "# print(image.shape)\n",
        "\n",
        "mse_noise_25 = mse(image, recon_image_25)\n",
        "ssim_noise_25 = ssim(image, recon_image_25,\n",
        "                  data_range=recon_image_25.max() - recon_image_25.min())\n",
        "\n",
        "mse_noise_50 = mse(image, recon_image_50)\n",
        "ssim_noise_50 = ssim(image, recon_image_50,\n",
        "                  data_range=recon_image_50.max() - recon_image_50.min())\n",
        "\n",
        "mse_noise_100 = mse(image, recon_image_100)\n",
        "ssim_noise_100 = ssim(image, recon_image_100,\n",
        "                  data_range=recon_image_100.max() - recon_image_100.min())\n",
        "\n",
        "mse_noise_150 = mse(image, recon_image_150)\n",
        "ssim_noise_150 = ssim(image, recon_image_150,\n",
        "                  data_range=recon_image_150.max() - recon_image_150.min())\n",
        "\n",
        "print(\"25 iterations mse\", mse_noise_25)\n",
        "print('25 iterations ssim', ssim_noise_25)\n",
        " \n",
        "print(\"50 iterations mse\", mse_noise_50)\n",
        "print('50 iterations ssim', ssim_noise_50)\n",
        "\n",
        "print(\"100 iterations mse\", mse_noise_100)\n",
        "print('100 iterations ssim', ssim_noise_100)\n",
        "\n",
        "print(\"150 iterations mse\", mse_noise_150)\n",
        "print('150 iterations ssim', ssim_noise_150)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Adaptive_Lambda_Fixed_everything_Fixed_Dictionary_Firm_Thresh_L_1_Dictionary_Learning_Final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
