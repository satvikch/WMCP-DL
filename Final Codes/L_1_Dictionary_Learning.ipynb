{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4Y0x9wMfNFx"
   },
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/satvikchemudupati/Documents/Praveen codes/ISBI codes and Results/Final Codes',\n",
       " '/Users/satvikchemudupati/anaconda3/lib/python311.zip',\n",
       " '/Users/satvikchemudupati/anaconda3/lib/python3.11',\n",
       " '/Users/satvikchemudupati/anaconda3/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/Users/satvikchemudupati/anaconda3/lib/python3.11/site-packages',\n",
       " '/Users/satvikchemudupati/anaconda3/lib/python3.11/site-packages/aeosa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_V_cWPQfNF0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# from ksvd import ApproximateKSVD\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numbers\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import numpy as np\n",
    "from skimage import io, util\n",
    "import sklearn.feature_extraction as sk\n",
    "# from ksvd import ApproximateKSVD\n",
    "import cv2\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPWFtDENfNF6"
   },
   "source": [
    "# KSVD CLASS \n",
    "\n",
    "## Ksvd class for training the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAeX2lYOfNF7"
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import orthogonal_mp_gram\n",
    "\n",
    "\n",
    "class ApproximateKSVD(object):\n",
    "    def __init__(self, n_components, max_iter=10, tol=1e-6,\n",
    "                 transform_n_nonzero_coefs = None, l=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_components:\n",
    "            Number of dictionary elements\n",
    "\n",
    "        max_iter:\n",
    "            Maximum number of iterations\n",
    "\n",
    "        tol:\n",
    "            tolerance for error\n",
    "\n",
    "        transform_n_nonzero_coefs:\n",
    "            Number of nonzero coefficients to target\n",
    "        \"\"\"\n",
    "        self.components_ = None\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.n_components = n_components\n",
    "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
    "        self.l = l\n",
    "\n",
    "    def _update_dict(self, X, D, gamma):\n",
    "        for j in range(self.n_components):\n",
    "            I = gamma[:, j] > 0\n",
    "            if np.sum(I) == 0:\n",
    "                continue\n",
    "\n",
    "            D[j, :] = 0\n",
    "            g = gamma[I, j].T\n",
    "#             print(gamma.shape)\n",
    "#             print(X.shape)\n",
    "#             print(len(I))\n",
    "            r = X[I, :] - gamma[I, :].dot(D)\n",
    "            d = r.T.dot(g)\n",
    "            d /= np.linalg.norm(d)\n",
    "            g = r.dot(d)\n",
    "            D[j, :] = d\n",
    "            gamma[I, j] = g.T\n",
    "        return D, gamma\n",
    "\n",
    "    def _initialize(self, X):\n",
    "        if min(X.shape) < self.n_components:\n",
    "            D = np.random.randn(self.n_components, X.shape[1])\n",
    "#             print(\"Dictionary:\", D.shape)\n",
    "        else:\n",
    "            u, s, vt = sp.sparse.linalg.svds(X, k=self.n_components)\n",
    "            D = np.dot(np.diag(s), vt)\n",
    "        D /= np.linalg.norm(D, axis=1)[:, np.newaxis]\n",
    "        return D\n",
    "    \n",
    "    def soft_thresh(self, x, s):\n",
    "        return np.sign(x) * np.maximum(np.abs(x) - s, 0.)  # shrinkage operation\n",
    "    \n",
    "    def fista(self, D, X, l, maxit = 100):\n",
    "        x = np.zeros(D.shape[0])\n",
    "        print(\"x shape\", x.shape)\n",
    "        print(\"l value\", l)\n",
    "    #     pobj = []\n",
    "        t = 1\n",
    "        z = x.copy()\n",
    "        L = linalg.norm(D) ** 2\n",
    "    #     time0 = time.time()\n",
    "        for i in range(maxit):\n",
    "            xold = x.copy()\n",
    "            product =  z.dot(D)\n",
    "#             print(product)\n",
    "#             print(\"z shape\", z.shape)\n",
    "#             print(\"D shape\", D.shape)\n",
    "#             print(\"Product shape\", product.shape)\n",
    "            sub = X - product\n",
    "#             print(\"X:\", X)\n",
    "#             print(\"-------------------------------\")\n",
    "#             print(\"sub:\", sub)\n",
    "            dotted = D.dot(sub.T) / L\n",
    "#             print(\"doted shape\", dotted.shape)\n",
    "            z =  dotted.T + z \n",
    "            x = self.soft_thresh(z, l / L)\n",
    "            t0 = t\n",
    "            t = (1. + sqrt(1. + 4. * t ** 2)) / 2.\n",
    "            z = x + ((t0 - 1.) / t) * (x - xold)\n",
    "    #         this_pobj = 0.5 * linalg.norm(A.dot(x) - b) ** 2 + l * linalg.norm(x, 1)\n",
    "    #         pobj.append((time.time() - time0, this_pobj))\n",
    "\n",
    "    #     times, pobj = map(np.array, zip(*pobj))\n",
    "        print(\"Final x shape\", x.shape)\n",
    "        return x\n",
    "\n",
    "#     def _transform(self, D, X, l, max_iterations = 1):\n",
    "        \n",
    "#         return self.fista(D, X, l, max_iterations)\n",
    "\n",
    "    def fit(self, X, l = 0.01):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: shape = [n_samples, n_features]\n",
    "        \"\"\"\n",
    "        # print(X)\n",
    "        # print(X.shape[1])\n",
    "        y = []\n",
    "        D = self._initialize(X)\n",
    "        l = self.l\n",
    "        transform_n_nonzero_coefs = self.transform_n_nonzero_coefs\n",
    "        for i in range(self.max_iter):\n",
    "            gamma = self.fista(D, X, l)\n",
    "            e = np.linalg.norm(X - gamma.dot(D))\n",
    "            y.append(e)\n",
    "            print(\"||Y - DX||2 for iteration {0} is: \".format(i+1), e)\n",
    "            if e < self.tol:\n",
    "                break\n",
    "            D, gamma = self._update_dict(X, D, gamma)\n",
    "\n",
    "        plt.plot(y)\n",
    "        plt.show()\n",
    "\n",
    "        self.components_ = D\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, l = 0.01):\n",
    "        return self.fista(self.components_, X, l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xcwd7gIfNGA"
   },
   "source": [
    "# Function to compute the number of patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQbvHq-zfNGC"
   },
   "outputs": [],
   "source": [
    "def _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches=None):\n",
    "\n",
    "    n_h = (i_h - p_h) // step + 1\n",
    "    n_w = (i_w - p_w) // step + 1\n",
    "    all_patches = n_h * n_w\n",
    "\n",
    "    return all_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3c1O12ZfNGG"
   },
   "source": [
    "# Function to extract the patches from Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls5A27l-fNGH"
   },
   "outputs": [],
   "source": [
    "def _extracting(arr, patch_shape=8, extraction_step=1):\n",
    "\n",
    "    arr_ndim = arr.ndim\n",
    "\n",
    "    if isinstance(patch_shape, numbers.Number):\n",
    "        patch_shape = tuple([patch_shape] * arr_ndim)\n",
    "    if isinstance(extraction_step, numbers.Number):\n",
    "        extraction_step = tuple([extraction_step] * arr_ndim)\n",
    "\n",
    "    patch_strides = arr.strides\n",
    "\n",
    "    slices = tuple(slice(None, None, st) for st in extraction_step)\n",
    "    indexing_strides = arr[slices].strides\n",
    "\n",
    "    patch_indices_shape = ((np.array(arr.shape) - np.array(patch_shape)) //\n",
    "                           np.array(extraction_step)) + 1\n",
    "\n",
    "    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n",
    "    strides = tuple(list(indexing_strides) + list(patch_strides))\n",
    "\n",
    "    patches = as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "    # patches = patches.reshape([-1] + list(patch_shape))\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ik-YyJ7vfNGL"
   },
   "source": [
    "# Function to call the extraction step and reshaping the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iv1kIgCffNGM"
   },
   "outputs": [],
   "source": [
    "def extract_patches(image, patch_size, step, max_patches=None, random_state=None):\n",
    "\n",
    "    i_h, i_w = image.shape[:2]\n",
    "    p_h, p_w = patch_size\n",
    "\n",
    "    # image = check_array(image, allow_nd=True)\n",
    "    image = image.reshape((i_h, i_w, -1))\n",
    "    n_colors = image.shape[-1]\n",
    "\n",
    "    extracted_patches = _extracting(image, patch_shape=(p_h, p_w, n_colors), extraction_step=step) # above function call\n",
    "    n_patches = _compute_n_patches(i_h, i_w, p_h, p_w, step, max_patches)\n",
    "    # print n_patches\n",
    "    # if max_patches:\n",
    "    #     rng = check_random_state(random_state)\n",
    "    #     i_s = rng.randint(i_h - p_h + step, size=n_patches)\n",
    "    #     j_s = rng.randint(i_w - p_w + step, size=n_patches)\n",
    "    #     patches = extracted_patches[i_s, j_s, 0]\n",
    "    # else:\n",
    "    patches = extracted_patches\n",
    "\n",
    "    patches = patches.reshape(-1, p_h, p_w, n_colors)\n",
    "    # print patches.shape\n",
    "    # remove the color dimension if useless\n",
    "    if patches.shape[-1] == 1:\n",
    "        return patches.reshape(n_patches, p_h, p_w)\n",
    "    else:\n",
    "        return patches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feuWwkedfNGQ"
   },
   "source": [
    "# Funtion for Reconstruction of the image from the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxlWAtyJfNGR"
   },
   "outputs": [],
   "source": [
    "def reconstruct_patches(patches, image_size, step):\n",
    "\n",
    "    i_h, i_w = image_size[:2]\n",
    "    p_h, p_w = patches.shape[1:3]\n",
    "    img = np.zeros(image_size)\n",
    "    # compute the dimensions of the patches array\n",
    "    n_h = int((i_h - p_h) / step + 1)\n",
    "    n_w = int((i_w - p_w) / step + 1)\n",
    "    for p, (i, j) in zip(patches, product(range(n_h), range(n_w))):\n",
    "        img[i * step:i * step + p_h, j * step:j * step + p_w] += p\n",
    "\n",
    "    for i in range(i_h):\n",
    "        for j in range(i_w):\n",
    "            img[i, j] /= float(min(i + step, p_h, i_h - i) *\n",
    "                               min(j + step, p_w, i_w - j))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEiVqk98fNGW"
   },
   "source": [
    "# If the input image is not noisy, function to add noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkHyT-IAfNGY",
    "outputId": "1f0cdbae-eaf6-43d1-946e-3e6a54f40755"
   },
   "outputs": [],
   "source": [
    "img = util.img_as_float(io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/input/Lenna.jpg\"))\n",
    "print(\"Adding Noise\")\n",
    "img_with_noise = util.random_noise(img, seed=1)\n",
    "io.imsave(\"noise.png\", img_with_noise)\n",
    "print(\"Done with noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjhdGWtrfNGi"
   },
   "source": [
    "# Loading of Image and Extracting patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1550900546580,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "A6LG3ScIfNGj",
    "outputId": "5f7e86ee-88aa-45a0-804c-ec997fa05107"
   },
   "outputs": [],
   "source": [
    "# imga = io.imread(\"F:/Internship/Data/brain_7% noise/brain_7_094.jpg\", 0)\n",
    "# print(imga.shape)\n",
    "\n",
    "# imgaa = cv2.imread(\"F:/Internship/Data/brain_7% noise/brain_7_094.jpg\", 0)\n",
    "# print(imgaa.shape)\n",
    "\n",
    "img = util.img_as_float(cv2.imread(\"unnamed.jpg\", 0))\n",
    "# image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/Prova.jpg\")\n",
    "\n",
    "res = extract_patches(img, (8, 8), 1)\n",
    "# width, height, col= res.shape\n",
    "# print(\"initial Image shape\", img.shape)\n",
    "print(\"Patches shape: \", res.shape)\n",
    "num_patch, p_h, p_w = res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZshBcSJfNGn"
   },
   "source": [
    "# Functions for converting 2d or 3d matrix to vector and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffKVMCyofNGo"
   },
   "outputs": [],
   "source": [
    "def matrix_to_vector(matrix, patch_size):\n",
    "    \n",
    "    list = np.split(matrix.reshape(-1,patch_size),matrix.shape[0])\n",
    "    \n",
    "    list1 = []\n",
    "    \n",
    "    \n",
    "    for arr in list:\n",
    "        bb = arr.flatten('F').reshape(patch_size**2,1)\n",
    "        list1.append(bb)\n",
    "\n",
    "    array = np.array(list1).squeeze()\n",
    "    \n",
    "    return array\n",
    "\n",
    "\n",
    "def vector_to_matrix_2d(vector,h,w):\n",
    "    \n",
    "    ab = np.reshape(vector,(h,w))\n",
    "    return ab.T\n",
    "\n",
    "def vector_to_matrix_3d(vector, h, w, col):\n",
    "\n",
    "    ab = np.reshape(vector,(h,w,col))\n",
    "#     print(ab.T)\n",
    "    return ab.transpose(0,2,1)\n",
    "\n",
    "\n",
    "# aa= np.array(range(27)).reshape(3,3,3)\n",
    "# print(aa)\n",
    "# print(\"------------------------\")\n",
    "\n",
    "# bb = matrix_to_vector(aa, 3)\n",
    "# print(bb)\n",
    "\n",
    "# ab = vector_to_matrix_3d(array, -1,3,3)\n",
    "# print(ab)\n",
    "\n",
    "# ba = vector_to_matrix_2d(bb[0], 3, 3)\n",
    "# print(ba)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzfOxD0EfNGr"
   },
   "source": [
    "# Pre-Processing step: Removing the mean from each value of the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1764
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2323,
     "status": "ok",
     "timestamp": 1550900577374,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "XFlFKfRpfNGs",
    "outputId": "e6df0f5b-5015-4af4-eb2c-d6b3280a4477"
   },
   "outputs": [],
   "source": [
    "imag = res[1]\n",
    "print(imag.shape)\n",
    "io.imshow(imag, cmap= 'gray')\n",
    "io.show()\n",
    "\n",
    "signals = matrix_to_vector(res, p_w)\n",
    "\n",
    "num_patches, patch_size = signals.shape\n",
    "\n",
    "print(\"Signals final shape\", signals.shape)\n",
    "mean = np.mean(signals, axis=0)[:, np.newaxis]\n",
    "print(\"Mean value shape: \", mean.shape)\n",
    "\n",
    "mean1 = vector_to_matrix_2d(mean,p_h,p_w)\n",
    "io.imshow(mean1, cmap = 'gray')\n",
    "io.show()\n",
    "\n",
    "signals = (signals.T - mean).T\n",
    "\n",
    "signals1 = vector_to_matrix_2d(signals[1], p_h, p_w)\n",
    "io.imshow(signals1, cmap = 'gray')\n",
    "io.show()\n",
    "\n",
    "signal_final = signals1 + mean1\n",
    "\n",
    "io.imshow(signal_final,  cmap= 'gray')\n",
    "io.show()\n",
    "\n",
    "if signal_final.all() == imag.all():\n",
    "    print(\"True\")\n",
    "else:\n",
    "    print(\"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuxW3PNOfNG0"
   },
   "source": [
    "# Applying KSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1150
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 307839,
     "status": "ok",
     "timestamp": 1550911799434,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "BF9E3-IJfNG1",
    "outputId": "9374764c-2d19-4bd5-e6b8-c07c91227bcd"
   },
   "outputs": [],
   "source": [
    "print(\"Applying KSVD\")\n",
    "aksvd = ApproximateKSVD(n_components=128, l=0.005)\n",
    "dictionary = aksvd.fit(signals).components_\n",
    "print(\"Done with learning\")\n",
    "# np.savetxt(\"test.txt\", dictionary)\n",
    "gamma = aksvd.transform(signals, l = 0.005)\n",
    "print(\"Found gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BuBlt-5fNG6",
    "outputId": "3d2576e9-1f2c-406c-8b51-01a55ba8e44d"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "adict = {}\n",
    "adict['dictionary'] = dictionary\n",
    "\n",
    "sio.savemat('Dictionaries/sigma_20/No. of coefficients = 10/sigma_20_patch_size_{0}x{1}.mat'.format(p_h,p_w), adict)\n",
    "\n",
    "bdict = sio.loadmat('Dictionaries/sigma_20/No. of coefficients = 10/sigma_20_patch_size_{0}x{1}.mat'.format(p_h,p_w))\n",
    "for rel in bdict:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1550911814922,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "JYYydlMsfNHG",
    "outputId": "fe40cb7d-9040-4788-dfcd-bf2ca7a283e8"
   },
   "outputs": [],
   "source": [
    "print(dictionary[1].shape)\n",
    "element = dictionary[1] + mean.T\n",
    "print(element.shape)\n",
    "element_1 = vector_to_matrix_2d(element, p_h, p_w)\n",
    "io.imshow(element_1, cmap = 'gray')\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFW6Bc1HfNHR"
   },
   "source": [
    "# Function for extracting images (patches) from Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmuKwOuufNHS"
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = os.path.join(folder, filename)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAyga37wfNHW"
   },
   "source": [
    "# Function to load the dictionary and convert to patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JH7aG7GfNHX",
    "outputId": "b3294e6f-7371-43e0-c08c-fb35387e74a0"
   },
   "outputs": [],
   "source": [
    "dictionary1 = dictionary.T + mean\n",
    "\n",
    "file = dictionary1\n",
    "print(file.shape)\n",
    "\n",
    "K = file.shape[1]\n",
    "# file1 = file.T\n",
    "# print(file1.shape)\n",
    "\n",
    "i = 0\n",
    "k = 0\n",
    "a = np.zeros((8, 16))\n",
    "b = np.zeros((8, 8))\n",
    "result = []\n",
    "#\n",
    "while k < file.shape[1]:\n",
    "    arr = file[:,k]\n",
    "    # a, b = split_array(arr)\n",
    "    a = np.reshape(arr, (-1, 8))\n",
    "    # b = np.reshape(b, (-1, 8))\n",
    "\n",
    "    result.append(a)\n",
    "\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4pu_erAfNHe"
   },
   "source": [
    "# Save each extracted patch as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQgxs_Y9fNHf",
    "outputId": "5ddc7b72-276f-4de3-d97e-a85603ad23d0"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(result.__len__()):\n",
    "    path = 'jup_images'\n",
    "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), result[i])\n",
    "    count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-hvn1V2fNHk"
   },
   "source": [
    "# Load the images and concatenate them to save as a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZI74C1f9fNHl",
    "outputId": "a81b2e99-ec6e-4776-cd3c-ce75936f43fb"
   },
   "outputs": [],
   "source": [
    "image = io.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/img_0.jpg\")\n",
    "\n",
    "images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images/\")\n",
    "\n",
    "BLUE = [0, 0, 0]\n",
    "final = []\n",
    "\n",
    "for img in images:\n",
    "    img = cv2.imread(img)\n",
    "    de_img= cv2.copyMakeBorder(img,1,1,1,1,cv2.BORDER_CONSTANT,value= BLUE)\n",
    "    final.append(de_img)\n",
    "    \n",
    "count = 0\n",
    "\n",
    "for i in range(final.__len__()):\n",
    "    path = 'jup_images_final'\n",
    "    io.imsave(os.path.join(path, 'img_{0}.jpg').format(i), final[i])\n",
    "    count += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "final_images = load_images_from_folder(\"C:/Users/DELL/PycharmProjects/ksvd_final/jup_images_final/\")\n",
    "\n",
    "new_im = Image.new('RGB', (80, 160))\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "count = 0\n",
    "\n",
    "i = 0\n",
    "k = 0\n",
    "j = 0\n",
    "\n",
    "for img in images:\n",
    "    imga = io.imread(img)\n",
    "    count += 1\n",
    "    print(count)\n",
    "    io.imshow(imga)\n",
    "    io.show()\n",
    "\n",
    "\n",
    "while j < 16:\n",
    "    while i < 8:\n",
    "        # fin = open(image)  # open the file\n",
    "        img = Image.open(final_images[k])\n",
    "        ext_img = img\n",
    "        new_im.paste(ext_img, (x_offset, y_offset))\n",
    "        x_offset += img.size[0]\n",
    "        i += 1\n",
    "        print('yes x_{0}'.format(i))\n",
    "        print('yes k_{0}'.format(k))\n",
    "        print(\"Offset x: \", x_offset)\n",
    "        k += 1\n",
    "    i = 0\n",
    "    y_offset += img.size[1]\n",
    "    x_offset = 0\n",
    "    j += 1\n",
    "    print('yes y_{0}'.format(j))\n",
    "    print(\"Y-offset\", y_offset)\n",
    "\n",
    "print(\"X:\", x_offset)\n",
    "print(\"Y:\", y_offset)\n",
    "\n",
    "new_im.save('test2.jpg')\n",
    "\n",
    "imagee = io.imread(\"test2.jpg\")\n",
    "io.imshow(imagee)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GvPnxwdfNHp"
   },
   "source": [
    "# Reconstruction of the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zz_xDTmjfNHq"
   },
   "source": [
    "# If stride > 1, image contrast reduces, to improve the contrast apply Histogram matching with noisy image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1550911829473,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "EGQYwFw-fNHr",
    "outputId": "0eae0b91-c28d-4887-83a2-fdf9bdea1e7e"
   },
   "outputs": [],
   "source": [
    "def convert_to_uint8(image_in):\n",
    "    temp_image = np.float64(np.copy(image_in))\n",
    "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "\n",
    "    return temp_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "reduced = (gamma.dot(dictionary)) + mean.T\n",
    "\n",
    "for ele in reduced:\n",
    "    if ele.any() < 0:\n",
    "        print(\"yes\")\n",
    "print(\"reconstruction patches shape:\", reduced.shape)\n",
    "red = reduced.reshape(res.shape)\n",
    "print('Final patch shape', red.shape)\n",
    "final_patches = vector_to_matrix_3d(reduced, -1,p_h,p_w)\n",
    "reduced_img = reconstruct_patches(final_patches, img.shape, 1)\n",
    "print(\"recon image shape:\", reduced_img.shape)\n",
    "# print(reduced)\n",
    "print(reduced_img.dtype)\n",
    "fin_recon_image = convert_to_uint8(reduced_img)\n",
    "cv2.imwrite('reduced_final_0.001_100_l1.jpg', fin_recon_image)\n",
    "io.imshow(fin_recon_image, cmap = 'gray')\n",
    "io.show()\n",
    "print(fin_recon_image)\n",
    "print(\"Done....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpmR1f4nfNHu"
   },
   "source": [
    "## Function to implement the histogram matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2VtsAcAfNHv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def hist_match(source, template):\n",
    "    oldshape = source.shape\n",
    "    source = source.ravel()\n",
    "    template = template.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n",
    "                                            return_counts=True)\n",
    "    t_values, t_counts = np.unique(template, return_counts=True)\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
    "    t_quantiles /= t_quantiles[-1]\n",
    "\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "\n",
    "    return interp_t_values[bin_idx].reshape(oldshape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7L1LEc0fNHy"
   },
   "source": [
    "## Reading both the images and calling the matching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMfTClMNfNH0",
    "outputId": "0c721005-266b-4112-e6d5-e0cb942a55a9"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import ascent\n",
    "import imageio as ios\n",
    "\n",
    "# Image Input\n",
    "image = cv2.imread(\"reduced_final_20_l1.jpg\", 0)\n",
    "\n",
    "image1 = cv2.imread(\"girl_face_noise_20.jpg\", 0)\n",
    "\n",
    "x, y= image.shape\n",
    "\n",
    "x1, y1 = image1.shape\n",
    "\n",
    "\n",
    "moddedimage = np.zeros([x, y], dtype=np.uint8)\n",
    "\n",
    "# gray levels\n",
    "gray_levels = 256\n",
    "# row times column\n",
    "mn = x * y\n",
    "\n",
    "source = image\n",
    "template = image1\n",
    "matched = hist_match(source, template)\n",
    "\n",
    "\n",
    "def ecdf(x):\n",
    "    vals, counts = np.unique(x, return_counts=True)\n",
    "    ecdf = np.cumsum(counts).astype(np.float64)\n",
    "    ecdf /= ecdf[-1]\n",
    "    return vals, ecdf\n",
    "\n",
    "\n",
    "x1, y1 = ecdf(source.ravel())\n",
    "x2, y2 = ecdf(template.ravel())\n",
    "x3, y3 = ecdf(matched.ravel())\n",
    "\n",
    "\n",
    "plt.imshow(source, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Source')\n",
    "plt.show()\n",
    "plt.imshow(template, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Noisy Image')\n",
    "plt.show()\n",
    "plt.imshow(matched, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Denoised Image')\n",
    "plt.show()\n",
    "\n",
    "# plt.imsave(\"final_output_match/matched_20.png\",matched)\n",
    "\n",
    "# image = cv2.imread(\"C:/Users/DELL/PycharmProjects/ksvd_final/matched.png\", 0)\n",
    "# cv2.imshow(\"image\", image)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2237,
     "status": "ok",
     "timestamp": 1550912203734,
     "user": {
      "displayName": "Chemudupati Satvik",
      "photoUrl": "",
      "userId": "03399879419590720762"
     },
     "user_tz": -330
    },
    "id": "bteNLcRAfNH4",
    "outputId": "dfa3c817-46a3-4a50-9100-b81490ac732a"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# print(matched.dtype)\n",
    "\n",
    "# data = matched\n",
    "# data = data/(data.max())\n",
    "# data = 255 * data\n",
    "# img = data.astype(np.uint8)\n",
    "\n",
    "def convert_to_uint8(image_in):\n",
    "    temp_image = np.float64(np.copy(image_in))\n",
    "    cv2.normalize(temp_image, temp_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "\n",
    "    return temp_image.astype(np.uint8)\n",
    "\n",
    "# count =0\n",
    "# for ele in matched:\n",
    "#     if ele.any() < 0:\n",
    "#         count += 1\n",
    "\n",
    "# print(count)\n",
    "\n",
    "original = cv2.imread(\"image.jpg\",0)\n",
    "# print(original.dtype)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(original, cmap ='gray')\n",
    "plt.show()\n",
    "\n",
    "image = cv2.imread(\"reduced_final_0.05_50_l1.jpg\", 0)\n",
    "contrast = convert_to_uint8(image)\n",
    "# print(original.dtype)\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.imshow(contrast, cmap ='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# noisy = cv2.imread(\"girl_face_noise_20.jpg\",0)\n",
    "# plt.imshow(noisy, cmap = 'gray')\n",
    "# plt.title(\"Nosiy\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# contrast = img\n",
    "# plt.imshow(contrast, cmap = 'gray')\n",
    "# plt.show()\n",
    "\n",
    "i_h, i_w = original.shape\n",
    "pixels = i_h * i_w\n",
    "\n",
    "print(original.min())\n",
    "print(original.max())\n",
    "print(\"------------------\")\n",
    "print(contrast.min())\n",
    "print(contrast.max())\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2 )\n",
    "    print(\"Mse:\", mse)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    result_psnr = (20 * math.log10(PIXEL_MAX / math.sqrt(mse)))\n",
    "    return result_psnr\n",
    "\n",
    "d=psnr(original,contrast)\n",
    "print(\"PSNR between original and reconstructed image:\", d)\n",
    "\n",
    "# d= psnr(original, noisy)\n",
    "# print(\"PSNR between original and noisy image:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rU3oPXmufNIA",
    "outputId": "bb740e0e-348c-4b1d-e00f-b3321acd1d6b"
   },
   "outputs": [],
   "source": [
    "# imagee = io.imread(\"F:/Internship/Data/brain_0% noise/brain_0_105.jpg\")\n",
    "# io.imshow(imagee)\n",
    "# io.show()\n",
    "# print(imagee.shape)\n",
    "\n",
    "image = cv2.imread('reduced_final_20_l1.jpg', 0)\n",
    "print(image.shape)\n",
    "io.imshow(image)\n",
    "io.show()\n",
    "\n",
    "# image = cv2.imread('girl_face_noise_20.jpg', 0)\n",
    "# print(image.shape)\n",
    "# io.imshow(image)\n",
    "# io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYVZblJHfNIJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "L_1_Dictionary_Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
